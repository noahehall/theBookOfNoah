# s3

- scalable, distributed object storage accessible from anywhere
- use cases
  - analytics/application data/log files/media hosting
  - backup and archival
  - software delivery: up to 5tb per object
  - static content/websites: html, css and clientside js
  - data lakes, cheap data store

## my thoughts

## links

- [landing page](https://aws.amazon.com/s3/?did=ap_card&trk=ap_card)
- [bucket policy examples](https://docs.aws.amazon.com/en_us/AmazonS3/latest/userguide/example-bucket-policies.html)
- [storage classes](https://aws.amazon.com/s3/storage-classes/)
- [versioning](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html)
- [naming rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html)
- [server side encryption](https://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html)

## best practices

- determine your folder hierarchy upfront: i.e your object prefixes
- s3 bucket policies vs iam policies
  - IAM policies: whenever you have alot of private buckets or prefer to centralize all of your policies
  - s3 bucket policies: simple cross-account access or complex policies that breach the IAM policy size limit
- object versioning
  - make sure to delete unused versions of an object to reduce costs
- automate object storage with lifecycle configurations
  - e.g. from standard > standard-IA > glacier: move to a lower cost longer term storage every 30 days
  - object types: periodic logs or any data that becomes less frequently accessed overtime
- static website hosting is a mismoner: you can still use client-side JS to load content dynamically
  - the idea is that there isnt a webserver responding to requests

### anti patterns

## features

- scalable storage with 11 9s of data durability
- multiple storage classes to fit R/W requirements
- various mechanisms for authnz
- filter data retrieved by lambda with S3 Select

### pricing

- depends on bucket versioning, object size, storage duration and storage class and the region of the s3 bucket
- storage class: think about storage duration and access patterns
  - latency of access: when you need something, do you need it immediately?
  - frequency of access: do you need stuff often
  - storage duration: long term vs short term
- costs are incurred for all objects in a bucket, including all object versions

## terms

## basics

- its all about buckets, folders (prefixes) and objects
- s3 is a flat hierarchy where bucket names must be unique across all aws accounts and regions

### buckets

- the root directory of a folder hierarchy
  - you then created a folder hierarchy via an object names
- bucket name: must be DNS compliant and unique across all of AWS, even tho the bucket itself is region specific
  - the bucket name becomes part of the URL for objects stored within

#### versioning

- enables uploading an item with the same prefix + object key
  - enabling versioning does not impact the location of the object
  - each successful upload creates an object with a new version ID
- object deletion:
  - deleting an object does not permanently remove it, instead a delete marker is placed on the object
  - to restore an object, you simply remove the marker
- version states
  - unversioned: object versioning is disabled
  - versioning-enabled: once enabled, it can never return to an unversioned state
  - versioning-suspended: all new objects will not have a version, but existing objects will keep their versions

### folders

- are just the prefixes you give to objects in buckets

### objects

- files stored in buckets
  - 5tb limit per object
- object key: the name of the object
- object url schema: `https://BUCKET_NAME.s3.REGION.amazonaws.com/PREFIX/OBJECT_KEY`

### authnz

- all s3 resources are private by default: only the user/aws account can view resources
- bucket permissions: determines bucket + overall object permissions
  - object ownership: acls are disabled by default
- object permissions: for specific objects
- public access: 3 step process
  - unblock public access on bucket
  - enable ACLs for object ownership, confusing this is done at the bucket level as well
  - go to a specific object and make it public

#### s3 bucket policies

- an alternative to IAM specific for s3 resources at the BUCKET level
- instead of attach policies to users/groups/roles, you attach them to buckets

### encryption

- provides encryption in transit and at rest
- at rest: three mutually exclusive options, depending on how you choose to manage the encryption keys.
  - Amazon S3-managed Keys (SSE-S3)
  - AWS KMS keys stored in AWS KMS (SSE-KMS)
  - Customer-provided keys (SSE-C)

### storage classes

- if you dont specify a storage class while uploading an object s3 uses the default (standard) class
- redundancy
  - one zone: the only storage class that doesnt store data redundantly across availability zones
  - all other classes store data across a minimum of 3 availability zones

#### standard

- general purpose for cloud apps, dynamic websites, content distribution, mobile/gaming apps, big data analytics

#### intelligent-tiering

- for data with unknown/changing access patterns
- s3 monitors object access patterns and moves them between 3 tiers
  - frequent access
  - infrequent access
  - archive instance

#### standard-infrequent access (standard IA)

- data that is access less frequently, but requires rapid access when needed
  - long term backups, disaster recovery files, etc
  - same durability, throughput and latency of s3 standard

#### one zone-infrequent access (one zone-IA)

- stores data in a single availability zone
  - secondary backups or easily recreatable data

#### glacier instance retrieval

- for archiving data that is rarely access and requires millisecond retrieval
  - cost savings up 68% off standard-IA storage class
  - same latency and throughput performance of standard-IA

#### glacier flexible retrieval

- low cost storage for archived data that is accessed 1 or 2 times per year
  - backup, disaster recovery
- data can be retrieved between 1-5 minutes for a cost
  - else it free but it takes 5-12 hours

#### glacier deep archive

- the lowest cost storage class for long-term retention (7 or more years) and digital preservation of data access 1-2 times per year
  - for meeting regulations/laws/compliance/financial/healthcare/public/etc
- data can be retrieved in about 12 hours

#### s3 on outposts

- object storage for on-premise Outposts environment
- for workloads with local data residency requirements or onpremise performance reasons

### object lifecycle

- automate moving objects/groups of objects to appropriate storage tiers
- transition actions: define when objects should transition to another storage class
- expiration actions: define when objects expire and should be permanently deleted

## considerations

- region
- bucket name: 3-63 chars, DNS compatible
- object ownership: either public or define an ACL
- IAM policies vs s3 bucket policies
  - iam attached to users/groups/roles
  - bucket policies.....attached to buckets ;)
- bucket versioning
- storage lifecycle

## integrations
